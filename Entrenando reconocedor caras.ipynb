{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2cb0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import webbrowser\n",
    "import datetime\n",
    "import pywhatkit\n",
    "import os\n",
    "import yfinance as yf\n",
    "import pyjokes\n",
    "\n",
    "ERROR_NO_ENTIENDO = \"No te entiendo\"\n",
    "ERROR_NO_RESULTADOS = \"No te entendi o no puedo encontrar resultados\"\n",
    "INFO_ESTOY_ESPERANDO = \"Estoy esperando tus ordenes\"\n",
    "\n",
    "\n",
    "class ObtencionVoz(object):\n",
    "\t\"\"\"Modulo para obtener la información de voz\"\"\"\n",
    "\tdef __init__(self, languaje_habla=\"spanish\",lenguaje_reconocimiento=\"es-MX\", tasa_muestreo=150,volume=1):\n",
    "\t\tsuper(ObtencionVoz, self).__init__()\n",
    "\t\tself.languaje_habla = languaje_habla\n",
    "\t\tself.tasa_muestreo = tasa_muestreo\n",
    "\t\tself.volume = volume\n",
    "\t\tself.lenguaje_reconocimiento = lenguaje_reconocimiento\n",
    "\n",
    "\tdef speaking(self,message):\n",
    "\t\tengine = pyttsx3.init()\n",
    "\t\tengine.setProperty('rate', self.tasa_muestreo)\n",
    "\t\tengine.setProperty('voice', self.languaje_habla)\n",
    "\t\tengine.setProperty('volume', self.volume)\n",
    "\t\tengine.say(message)\n",
    "\t\tengine.runAndWait()\n",
    "\n",
    "\tdef transform(self):\n",
    "\t\tr = sr.Recognizer()\n",
    "\t\twith sr.Microphone() as source:\n",
    "\t\t\tr.adjust_for_ambient_noise(source)\n",
    "\t\t\tr.pause_threshold = 0.8\n",
    "\t\t\tsaid = r.listen(source)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tq = r.recognize_google(said, language=self.lenguaje_reconocimiento)\n",
    "\t\t\t\treturn q\n",
    "\t\t\texcept sr.UnknownValueError:\n",
    "\t\t\t\treturn ERROR_NO_ENTIENDO\n",
    "\t\t\texcept sr.RequestError:\n",
    "\t\t\t\treturn ERROR_NO_RESULTADOS\n",
    "\t\t\texcept e:\n",
    "\t\t\t\treturn INFO_ESTOY_ESPERANDO\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8706615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenes \n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import numpy as np\n",
    "#utilerias\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "\n",
    "MUESTRAS_NUMERO = 800\n",
    "\n",
    "class ReconocimientoFacial(object):\n",
    "\t\"\"\"Modulo para hacer el reconocimiento facial y la autenticación\"\"\"\n",
    "\tdef __init__(self, numero_muestras=MUESTRAS_NUMERO):\n",
    "\t\tsuper(ReconocimientoFacial, self).__init__()\n",
    "\t\tself.voz = ObtencionVoz()\n",
    "\t\tself.numero_muestras = numero_muestras\n",
    "\n",
    "\tdef getHash(self):\n",
    "\t\treturn hashlib.md5(datetime.now().__str__().encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\tdef prepare_working_directory(self,personName):\n",
    "\t\t\"\"\" Crea las carpetas para almacenar las imagenes del directorio.\"\"\"\n",
    "\t\tdataPath = os.path.join(os.getcwd(),\"data\")\n",
    "\t\tpersonPath = os.path.join(dataPath,personName)\n",
    "\t\tif not os.path.exists(personPath):\n",
    "\t\t\tprint('Carpeta creada: ',personPath)\n",
    "\t\t\tos.makedirs(personPath)\n",
    "\t\treturn dataPath,personPath\n",
    "\n",
    "\tdef get_samples_faces_from_cam(self,personPath):\n",
    "\t\t\"\"\"Realiza la toma de las capturas de la camara.\"\"\"\n",
    "\t\tlabels = [\"seri@\",\"sonriente\",\"riendo\",\"enojad@\", \"Guino un ojo\",\"Guino el otro ojo\",\"Con lentes\",\"Sin Lentes\",\"Hablando\"]\n",
    "\t\tperiodo = MUESTRAS_NUMERO//len(labels)\n",
    "\t\tindex=0\n",
    "\t\tcap = cv2.VideoCapture(-1)\n",
    "\t\tfaceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\t\tcount = 0\n",
    "\t\tconta = 0 \n",
    "\t\tspeak = True\n",
    "\t\twhile True:\n",
    "\t\t\tret, frame = cap.read()\n",
    "\t\t\tif ret == False: break\n",
    "\t\t\tframe =  imutils.resize(frame, width=640)\n",
    "\t\t\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tauxFrame = frame.copy()\n",
    "\t\t\tfaces = faceClassif.detectMultiScale(gray,1.3,5)\n",
    "\t\t\tfor (x,y,w,h) in faces:\n",
    "\t\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\t\t\t\trostro = auxFrame[y:y+h,x:x+w]\n",
    "\t\t\t\trostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)\n",
    "\t\t\t\tcv2.imwrite(personPath + '/rotro_{}_{}.jpg'.format(self.getHash(),count),rostro)\n",
    "\t\t\t\tcount = count + 1\n",
    "\t\t\t\tconta += 1\n",
    "\t\t\tif conta == periodo:\n",
    "\t\t\t\tindex= (index+1)%(len(labels))\n",
    "\t\t\t\tconta = 0\n",
    "\t\t\t\tspeak = True\n",
    "\t\t\tif speak:\n",
    "\t\t\t\tspeak = False\n",
    "\t\t\t\thilo1 = threading.Thread(target=self.voz.speaking,args=(\"Podrias poner tu cara \"+labels[index],))\n",
    "\t\t\t\thilo1.start()\n",
    "\t\t\t\t\n",
    "\t\t\tcv2.putText(frame,labels[index]+\" count: \"+str(count)+\" index: \"+str(index), (114,430), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "\t\t\tcv2.imshow('frame',frame)\n",
    "\t\t\tk = cv2.waitKey(1)\n",
    "\t\t\tif k == 27 or count >= MUESTRAS_NUMERO:\n",
    "\t\t\t\tbreak\n",
    "\t\tcap.release()\n",
    "\t\tcv2.destroyAllWindows() \n",
    "\n",
    "\tdef train_model(self,working_directory,face_recognizer = cv2.face.LBPHFaceRecognizer_create(),model_xml=\"modeloLBPHFace.xml\"):\n",
    "\t\tdataPath = working_directory[0]\n",
    "\t\tpersonPath = working_directory[1]\n",
    "\t\tpeopleList = [directorio for directorio in os.listdir(dataPath) if not directorio.startswith(\".\")]\n",
    "\t\tprint('Lista de personas: ', peopleList)\n",
    "\t\tlabels = []\n",
    "\t\tfacesData = []\n",
    "\t\tlabel = 0\n",
    "\t\tfor nameDir in peopleList:\n",
    "\t\t\tpersonPath = dataPath + '/' + nameDir\n",
    "\t\t\tprint('Leyendo las imágenes')\n",
    "\t\t\tfor fileName in os.listdir(personPath):\n",
    "\t\t\t\tlabels.append(label)\n",
    "\t\t\t\tfacesData.append(cv2.imread(personPath+'/'+fileName,0))\n",
    "\t\t\t\t#image = cv2.imread(personPath+'/'+fileName,0)\n",
    "\t\t\t\t#cv2.imshow('image',image)\n",
    "\t\t\t\t#cv2.waitKey(10)\n",
    "\t\t\tlabel = label + 1\n",
    "\t\t\t\n",
    "\t\t#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\t\t#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\t\t#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\t\tprint(\"Entrenando...\")\n",
    "\t\tface_recognizer.train(facesData, np.array(labels))\n",
    "\t\tface_recognizer.write(model_xml)\n",
    "\t\tprint(\"Modelo almacenado...\")\n",
    "\n",
    "\tdef reconocimiento_facial(self,working_directory):\n",
    "\t\tdataPath = working_directory[0]\n",
    "\t\tpersonPath = working_directory[1]\n",
    "\t\timagePaths = os.listdir(dataPath)\n",
    "\t\tprint('imagePaths=',imagePaths)\n",
    "\t\t#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\t\t#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\t\t#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\t\t# Leyendo el modelo\n",
    "\t\t#face_recognizer.read('modeloEigenFace.xml')\n",
    "\t\t#face_recognizer.read('modeloFisherFace.xml')\n",
    "\t\tface_recognizer.read('modeloLBPHFace.xml')\n",
    "\t\tcap = cv2.VideoCapture(0)\n",
    "\t\t#cap = cv2.VideoCapture('Video.mp4')\n",
    "\n",
    "\t\tfaceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\t\twhile True:\n",
    "\t\t\tret,frame = cap.read()\n",
    "\t\t\tif ret == False: break\n",
    "\t\t\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\tauxFrame = gray.copy()\n",
    "\t\t\tfaces = faceClassif.detectMultiScale(gray,1.3,5)\n",
    "\t\t\tfor (x,y,w,h) in faces:\n",
    "\t\t\t\trostro = auxFrame[y:y+h,x:x+w]\n",
    "\t\t\t\trostro = cv2.resize(rostro,(150,150),interpolation= cv2.INTER_CUBIC)\n",
    "\t\t\t\tresult = face_recognizer.predict(rostro)\n",
    "\t\t\t\tcv2.putText(frame,'{}'.format(result),(x,y-5),1,1.3,(255,255,0),1,cv2.LINE_AA)\n",
    "\t\t\t\t'''\n",
    "\t\t\t\t# EigenFaces\n",
    "\t\t\t\tif result[1] < 5700:\n",
    "\t\t\t\t\tcv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
    "\t\t\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
    "\t\t\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\t\t\t\t'''\n",
    "\t\t\t\t'''\n",
    "\t\t\t\t# FisherFace\n",
    "\t\t\t\tif result[1] < 500:\n",
    "\t\t\t\t\tcv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
    "\t\t\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
    "\t\t\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\t\t\t\t'''\n",
    "\t\t\t\t# LBPHFace\n",
    "\t\t\t\tif result[1] < 70:\n",
    "\t\t\t\t\tcv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
    "\t\t\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tcv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
    "\t\t\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\t\t\t\t\n",
    "\t\t\tcv2.imshow('frame',frame)\n",
    "\t\t\tk = cv2.waitKey(1)\n",
    "\t\t\tif k == 27:\n",
    "\t\t\t\tbreak\n",
    "\t\tcap.release()\n",
    "\t\tcv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72121e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo.....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "face_recognition = ReconocimientoFacial()\n",
    "\n",
    "working_directory = face_recognition.prepare_working_directory(\"david\")\n",
    "#face_recognition.get_samples_faces_from_cam(working_directory[1])\n",
    "print(\"Entrenando modelo.....\")\n",
    "#face_recognition.train_model(working_directory,face_recognizer = cv2.face.LBPHFaceRecognizer_create(),model_xml=\"modeloLBPHFace.xml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146a1e4",
   "metadata": {},
   "source": [
    "## Fase de evalucion del modelo \n",
    "\n",
    "Evaluando los modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da3856",
   "metadata": {},
   "source": [
    "Modelos a realizar la evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d4771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [cv2.face.EigenFaceRecognizer_create(),cv2.face.FisherFaceRecognizer_create(),cv2.face.LBPHFaceRecognizer_create(),]\n",
    "rutas_modelos = ['modeloEigenFace.xml','modeloFisherFace.xml','modeloLBPHFace.xml',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c444b4bf",
   "metadata": {},
   "source": [
    "Entrenado los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73107f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing  import Pool\n",
    "def f(x):\n",
    "    modelo = x[0]\n",
    "    ruta = x[1]\n",
    "    face_recognition = ReconocimientoFacial()\n",
    "    face_recognition.train_model(working_directory,\n",
    "                             face_recognizer = modelo\n",
    "                             ,model_xml=ruta)\n",
    "    return ruta\n",
    "\n",
    "with Pool(32) as p:\n",
    "    result = p.map_async(f, [(m,r) for m,r in zip(modelos,rutas_modelos)])\n",
    "    result.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260287c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69601845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.face.EigenFaceRecognizer 0x7f862b749770> modeloEigenFace.xml\n",
      "< cv2.face.FisherFaceRecognizer 0x7f862b749c10> modeloFisherFace.xml\n",
      "< cv2.face.LBPHFaceRecognizer 0x7f862b7496b0> modeloLBPHFace.xml\n"
     ]
    }
   ],
   "source": [
    "for modelo, rutas_entrenamiento_guardar in zip(modelos,rutas_modelos):\n",
    "    print(modelo, rutas_entrenamiento_guardar)\n",
    "    \"\"\"\n",
    "    face_recognition.train_model(working_directory,\n",
    "                             face_recognizer = modelo\n",
    "                             ,model_xml=rutas_entrenamiento_guardar)\n",
    "                             \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41ab497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de personas:  ['david']\n",
      "Leyendo las imágenes\n",
      "Entrenando...\n",
      "Modelo almacenado...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    face_recognition.train_model(working_directory,\n",
    "                             face_recognizer = modelos[0]\n",
    "                             ,model_xml=rutas_modelos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e6c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a769e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc493e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c234343",
   "metadata": {},
   "source": [
    "Carga de data set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "52d21600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def load_data(dir_path, IMG_SIZE):\n",
    "    faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    X = []\n",
    "    yo = []\n",
    "    i = 0\n",
    "    labels = dict()\n",
    "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
    "        if not path.startswith('.'):\n",
    "            labels[i] = path\n",
    "            for file in os.listdir(dir_path + path):\n",
    "                if not file.startswith('.'):\n",
    "                    img = cv2.imread(dir_path + path + '/' + file)\n",
    "                    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    auxFrame = gray.copy()\n",
    "                    faces = faceClassif.detectMultiScale(gray,1.3,5)\n",
    "                    for (x,y,w,h) in faces:\n",
    "                        rostro = auxFrame[y:y+h,x:x+w]\n",
    "                        rostro = cv2.resize(rostro,(150,150),interpolation= cv2.INTER_CUBIC)\n",
    "                        X.append(rostro)\n",
    "                        yo.append(i)\n",
    "            i += 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f'{len(X)} images loaded from {dir_path} directory.')\n",
    "    return X, y, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a60cbce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bec38a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/alan/Documents/source_code/python/data\"\n",
    "TRAIN_DIR = (f'{PATH}/Training/')\n",
    "TEST_DIR = (f'{PATH}/Training/Testing/')\n",
    "#IMG_SIZE= (48, 48)\n",
    "IMG_SIZE= (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4e0c01a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6/6 [00:11<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603 images loaded from /home/alan/Documents/source_code/python/data/Training/ directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, train_labels = load_data(TRAIN_DIR, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1d992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c6e9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "#face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "# Leyendo el modelo\n",
    "#face_recognizer.read('modeloEigenFace.xml')\n",
    "#face_recognizer.read('modeloFisherFace.xml')\n",
    "face_recognizer.read('modeloLBPHFace.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b75fff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read('modeloLBPHFace.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f0d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff3329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "78dfec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento_evaluado = [ face_recognizer.predict(i)[1] for i in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c6bf7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in entrenamiento_evaluado if i < 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f6d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8011fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9a4ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"/home/alan/Documents/source_code/python/data/\"\n",
    "cascPath = \"/home/alan/Documents/source_code/python/data/casc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9895d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34331/3336580528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7947ffeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cascPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34331/4283542191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfaceCascade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcascPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m faces = faceCascade.detectMultiScale(\n\u001b[1;32m      3\u001b[0m     \u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscaleFactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mminNeighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cascPath' is not defined"
     ]
    }
   ],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.cv.CV_HAAR_SCALE_IMAGE\n",
    ")\n",
    "for (x, y, w, h) in faces:\n",
    "     cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edf164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534d367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de6a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507d204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba92418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6a623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172b713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd4ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e773a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3227d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248d7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df077b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e02d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f03bda",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'predict'\n> Overload resolution failed:\n>  - face_FaceRecognizer.predict() missing required argument 'src' (pos 1)\n>  - face_FaceRecognizer.predict() missing required argument 'src' (pos 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34331/1548584363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'predict'\n> Overload resolution failed:\n>  - face_FaceRecognizer.predict() missing required argument 'src' (pos 1)\n>  - face_FaceRecognizer.predict() missing required argument 'src' (pos 1)\n"
     ]
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a1754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e44b8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42199402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdd882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
