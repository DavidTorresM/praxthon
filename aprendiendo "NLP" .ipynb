{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70d61a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.es import Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de3212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Spanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4aaac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"esto cuesta $10 pesos mexicanos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac6a7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "esto cuesta $10 pesos mexicanos"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71274280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(True, False),\n",
       " (True, False),\n",
       " (False, False),\n",
       " (False, False),\n",
       " (True, False),\n",
       " (True, False)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i.is_alpha,i.is_punct) for i in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed79f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1385533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2435d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cdf661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Quiero jugar videojuegos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bef8c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiero VERB 0.0\n",
      "jugar VERB 0.0\n",
      "videojuegos NOUN 0.0\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "846534ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/alan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/alan/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12e99d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec36255",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = \"In the previous chapter, we saw examples of some common NLP applications that we might encounter in everyday life. If we were asked to build such an application, think about how we would approach doing so at our organization. We would normally walk through the requirements and break the problem down into several sub-problems, then try to develop a step-by-step procedure to solve them. Since language processing is involved, we would alsolist all the forms of text processing needed at each step. This step-by-step processing of text is known as pipeline. It is the series of steps involved inbuilding any NLP model. These steps are common in every NLP project, so it makes sense to study them in this chapter. Understanding some common proceduresin any NLP pipeline will enable us to get started on any NLP problem encountered in the workplace. Laying out and developing a text-processing pipeline is seen as a starting point for any NLP application development process. In thischapter, we will learn about the various steps involved and how they play  important roles in solving the NLP problem and we’ll see a few guidelinesabout when and how to use which step. In later chapters, we’ll discuss  specific pipelines for various NLP tasks (e.g., Chapters 4–7).\"\n",
    "my_sentences = sent_tokenize(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7619c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the previous chapter, we saw examples of some common NLP applications that we might encounter in everyday life.\n",
      "['In', 'the', 'previous', 'chapter', ',', 'we', 'saw', 'examples', 'of', 'some', 'common', 'NLP', 'applications', 'that', 'we', 'might', 'encounter', 'in', 'everyday', 'life', '.']\n",
      "If we were asked to build such an application, think about how we would approach doing so at our organization.\n",
      "['If', 'we', 'were', 'asked', 'to', 'build', 'such', 'an', 'application', ',', 'think', 'about', 'how', 'we', 'would', 'approach', 'doing', 'so', 'at', 'our', 'organization', '.']\n",
      "We would normally walk through the requirements and break the problem down into several sub-problems, then try to develop a step-by-step procedure to solve them.\n",
      "['We', 'would', 'normally', 'walk', 'through', 'the', 'requirements', 'and', 'break', 'the', 'problem', 'down', 'into', 'several', 'sub-problems', ',', 'then', 'try', 'to', 'develop', 'a', 'step-by-step', 'procedure', 'to', 'solve', 'them', '.']\n",
      "Since language processing is involved, we would alsolist all the forms of text processing needed at each step.\n",
      "['Since', 'language', 'processing', 'is', 'involved', ',', 'we', 'would', 'alsolist', 'all', 'the', 'forms', 'of', 'text', 'processing', 'needed', 'at', 'each', 'step', '.']\n",
      "This step-by-step processing of text is known as pipeline.\n",
      "['This', 'step-by-step', 'processing', 'of', 'text', 'is', 'known', 'as', 'pipeline', '.']\n",
      "It is the series of steps involved inbuilding any NLP model.\n",
      "['It', 'is', 'the', 'series', 'of', 'steps', 'involved', 'inbuilding', 'any', 'NLP', 'model', '.']\n",
      "These steps are common in every NLP project, so it makes sense to study them in this chapter.\n",
      "['These', 'steps', 'are', 'common', 'in', 'every', 'NLP', 'project', ',', 'so', 'it', 'makes', 'sense', 'to', 'study', 'them', 'in', 'this', 'chapter', '.']\n",
      "Understanding some common proceduresin any NLP pipeline will enable us to get started on any NLP problem encountered in the workplace.\n",
      "['Understanding', 'some', 'common', 'proceduresin', 'any', 'NLP', 'pipeline', 'will', 'enable', 'us', 'to', 'get', 'started', 'on', 'any', 'NLP', 'problem', 'encountered', 'in', 'the', 'workplace', '.']\n",
      "Laying out and developing a text-processing pipeline is seen as a starting point for any NLP application development process.\n",
      "['Laying', 'out', 'and', 'developing', 'a', 'text-processing', 'pipeline', 'is', 'seen', 'as', 'a', 'starting', 'point', 'for', 'any', 'NLP', 'application', 'development', 'process', '.']\n",
      "In thischapter, we will learn about the various steps involved and how they play  important roles in solving the NLP problem and we’ll see a few guidelinesabout when and how to use which step.\n",
      "['In', 'thischapter', ',', 'we', 'will', 'learn', 'about', 'the', 'various', 'steps', 'involved', 'and', 'how', 'they', 'play', 'important', 'roles', 'in', 'solving', 'the', 'NLP', 'problem', 'and', 'we', '’', 'll', 'see', 'a', 'few', 'guidelinesabout', 'when', 'and', 'how', 'to', 'use', 'which', 'step', '.']\n",
      "In later chapters, we’ll discuss  specific pipelines for various NLP tasks (e.g., Chapters 4–7).\n",
      "['In', 'later', 'chapters', ',', 'we', '’', 'll', 'discuss', 'specific', 'pipelines', 'for', 'various', 'NLP', 'tasks', '(', 'e.g.', ',', 'Chapters', '4–7', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in my_sentences:\n",
    "   print(sentence)\n",
    "   print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8f68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028d363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "363f10ae",
   "metadata": {},
   "source": [
    "Stemming  derivacion\n",
    "    Cambiar palabras por sus equivalentes:\n",
    "        Automoviles \n",
    "        Automovil \n",
    "        => Automovil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf6567e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car revolut\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "word1, word2 = \"cars\", \"revolution\"\n",
    "print(stemmer.stem(word1), stemmer.stem(word2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8e08e",
   "metadata": {},
   "source": [
    "Lemmatization mapea la diferentes formas de una palabra o palabra base a un lemma\n",
    "\n",
    "    Ejemplo:\n",
    "        Bueno => mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa1bd5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\")) #a is for adjective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d009220",
   "metadata": {},
   "source": [
    "### Normalizacion de texto\n",
    "\n",
    "Cuando se llega a una representacion canonica del texto. Todas las variaciones en 1 representación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae1f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39762eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c6f113e",
   "metadata": {},
   "source": [
    "##### NER Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5966555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charles Charles PROPN Xxxxx True False\n",
      "Spencer Spencer PROPN Xxxxx True False\n",
      "Chaplin Chaplin PROPN Xxxxx True False\n",
      "was be AUX xxx True True\n",
      "born bear VERB xxxx True False\n",
      "on on ADP xx True True\n",
      "16 16 NUM dd False False\n",
      "April April PROPN Xxxxx True False\n",
      "1889 1889 NUM dddd False False\n",
      "toHannah toHannah PROPN xxXxxxx True False\n",
      "Chaplin Chaplin PROPN Xxxxx True False\n",
      "( ( PUNCT ( False False\n",
      "born bear VERB xxxx True False\n",
      "Hannah Hannah PROPN Xxxxx True False\n",
      "HarrietPedlingham HarrietPedlingham PROPN XxxxxXxxxx True False\n",
      "Hill Hill PROPN Xxxx True False\n",
      ") ) PUNCT ) False False\n",
      "and and CCONJ xxx True True\n",
      "Charles Charles PROPN Xxxxx True False\n",
      "Chaplin Chaplin PROPN Xxxxx True False\n",
      "Sr Sr PROPN Xx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Charles Spencer Chaplin was born on 16 April 1889 toHannah Chaplin (born Hannah HarrietPedlingham Hill) and Charles Chaplin Sr')\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2852ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = doc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16f6bc",
   "metadata": {},
   "source": [
    "##### Hot encoding\n",
    "Mapea las palabras a numeros(Raramente usados)\n",
    "### BAG of word BoW\n",
    "SOn para clasificar textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466ef5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817defcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9e79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777b64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
